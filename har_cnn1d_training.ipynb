{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cria repositório de reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.enums import Datas\n",
    "from utils.checkpoints import verifyPath\n",
    "\n",
    "teste_size = 0\n",
    "main_data = Datas.MOTION\n",
    "path_reports = f\"report_results/{Datas.HAR.value}/{main_data.value}_{teste_size}/\"\n",
    "\n",
    "split_path = path_reports.split(\"/\")\n",
    "partial_path = \"\"\n",
    "for i, part in enumerate(split_path):\n",
    "    partial_path += part + \"/\"\n",
    "    verifyPath(partial_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treina Pretexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Hiperparâmentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from models.cnn1d import CNN1d\n",
    "from utils.enums import Datas, Sets, ModelTypes\n",
    "from data_modules.pretext import HarDataModule as HarDataModulePretext\n",
    "from transforms.har import rotation, flip, noise_addition, permutation, scaling, time_warp, negation\n",
    "\n",
    "printQtd = 1\n",
    "num_epoch = 100\n",
    "batch_size = 32\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Optim\n",
    "learning_rate = 0.02\n",
    "step_size = 20\n",
    "gamma = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carrega Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = [rotation, flip, noise_addition, permutation, scaling, time_warp, negation]\n",
    "data_module = HarDataModulePretext(batch_size=batch_size, main_data = main_data)\n",
    "train_dl, train_ds = data_module.get_dataloader(set=Sets.TRAIN.value, shuffle=True, transforms=transforms)\n",
    "test_dl, test_ds   = data_module.get_dataloader(set=Sets.TEST.value, shuffle=False, transforms=transforms)\n",
    "num_classes = len(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p = CNN1d(data_label=main_data.value, num_classes=num_classes, require_grad=True, type=ModelTypes.PRETEXT.value)\n",
    "print(model_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightning as L\n",
    "# trainer = L.Trainer(\n",
    "#     max_epochs=10,\n",
    "#     accelerator='cpu',\n",
    "#     log_every_n_steps=1        \n",
    "# )\n",
    "# trainer.fit(model=model, train_dataloaders=train_dl)\n",
    "\n",
    "optimizer, lr_scheduler = model_p.configure_optimizers(step_size=step_size, gamma=gamma, learning_rate=learning_rate)\n",
    "optimizer, lr_scheduler = optimizer[0], lr_scheduler[0]\n",
    "\n",
    "train_errors = []\n",
    "validation_errors = []\n",
    "best_val_loss = 500\n",
    "n_total_steps = len(train_dl)\n",
    "for epoch in range(num_epoch):\n",
    "    # Treinamento\n",
    "    model_p.train()\n",
    "    train_loss = 0\n",
    "    for i, batch in enumerate(train_dl):\n",
    "        loss = model_p.training_step(batch)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % math.floor(n_total_steps/printQtd) == 0:\n",
    "            print (f'Epoch [{epoch+1:4d}/{num_epoch}], Step [{i+1:4d}/{n_total_steps}], Loss: {loss.item():.4f}', end= \"\" if n_total_steps/printQtd+i >= n_total_steps else \"\\n\")\n",
    "\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Validação\n",
    "    model_p.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dl:\n",
    "            val_loss += model_p.validation_step(batch)\n",
    "    \n",
    "    val_loss /= len(test_dl)\n",
    "    print(f' Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "    train_errors.append(train_loss/len(train_dl))\n",
    "    validation_errors.append(val_loss.item())\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model_p.state_dict()  # Salva os parâmetros do modelo\n",
    "\n",
    "model_p.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accTotal = 0\n",
    "predicted_values = []\n",
    "real_values = []\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(num_classes)]\n",
    "    n_class_samples = [0 for i in range(num_classes)]\n",
    "    n_each_class_samples = [0 for i in range(num_classes)]\n",
    "\n",
    "    for data, labels in test_dl:\n",
    "        outputs = model_p(data)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        for pred, real in zip (predicted, labels):\n",
    "            predicted_values.append(pred.item())\n",
    "            real_values.append(real.item())\n",
    "\n",
    "        for i in range(labels.shape[0]):\n",
    "            label = labels[i]\n",
    "            pred  = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "            n_each_class_samples[pred] += 1\n",
    "\n",
    "    accTotal = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {accTotal} %')\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {test_ds.getLabel(i)} ({n_class_correct[i]}/{n_class_samples[i]} | {n_each_class_samples[i]}): {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salva resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p.save_backbone(accuracy=accTotal, batch_size=batch_size, num_epoch=num_epoch)\n",
    "\n",
    "pred_reports = pd.DataFrame({\n",
    "    Sets.REAL.value: real_values,\n",
    "    Sets.PREDICTION.value : predicted_values\n",
    "})\n",
    "pred_reports.to_csv(f\"{path_reports}/predictions_{ModelTypes.PRETEXT.value}.dat\", sep=\" \", index=False)\n",
    "\n",
    "train_reports = pd.DataFrame({\n",
    "    Sets.TRAIN.value : train_errors,\n",
    "    Sets.VALIDATION.value : validation_errors\n",
    "})\n",
    "train_reports.to_csv(f\"{path_reports}/errors_{ModelTypes.PRETEXT.value}.dat\", sep=\" \", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treina Downstream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hiperparâmentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_modules.har import HarDataModule as HarDataModuleDownstram\n",
    "from utils.enums import Datas, Sets, ModelTypes\n",
    "from models.cnn1d import CNN1d\n",
    "\n",
    "printQtd = 1\n",
    "isFreezing = True\n",
    "batch_size = 10\n",
    "num_epoch = 500\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Optim config\n",
    "learning_rate_bb = 0.02\n",
    "step_size_bb = 120\n",
    "gamma_bb = 0.5\n",
    "\n",
    "learning_rate_ds = 0.01\n",
    "step_size_ds = 100\n",
    "gamma_ds = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carrega Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = HarDataModuleDownstram(batch_size=64)\n",
    "train_dl, train_ds = data_module.get_dataloader(set=Sets.TRAIN.value, shuffle=True)\n",
    "test_dl, test_ds   = data_module.get_dataloader(set=Sets.TEST.value, shuffle=True)\n",
    "num_classes = len(train_ds.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN1d(\n",
      "  (criterion): CrossEntropyLoss()\n",
      "  (backbone): Backbone(\n",
      "    (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv1): Conv1d(6, 12, kernel_size=(2,), stride=(1,))\n",
      "    (conv2): Conv1d(12, 24, kernel_size=(2,), stride=(1,))\n",
      "    (conv3): Conv1d(24, 48, kernel_size=(2,), stride=(1,))\n",
      "  )\n",
      "  (pred_head): ProjectionHead(\n",
      "    (linear1): Linear(in_features=288, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN1d(\n",
    "    data_label=main_data.value, \n",
    "    num_classes=num_classes, \n",
    "    require_grad=isFreezing, \n",
    "    type=ModelTypes.DOWNSTREAM.value\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [   1/500], Step [   1/1], Loss: 1.8195"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sr_rosa/.local/lib/python3.10/site-packages/lightning/pytorch/core/module.py:436: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Validation Loss: 1.7819\n",
      "Epoch [   2/500], Step [   1/1], Loss: 1.7952 Validation Loss: 1.7599\n",
      "Epoch [   3/500], Step [   1/1], Loss: 1.7622 Validation Loss: 1.7307\n",
      "Epoch [   4/500], Step [   1/1], Loss: 1.7260 Validation Loss: 1.7122\n",
      "Epoch [   5/500], Step [   1/1], Loss: 1.7029 Validation Loss: 1.7006\n",
      "Epoch [   6/500], Step [   1/1], Loss: 1.6862 Validation Loss: 1.6926\n",
      "Epoch [   7/500], Step [   1/1], Loss: 1.6733 Validation Loss: 1.6873\n",
      "Epoch [   8/500], Step [   1/1], Loss: 1.6636 Validation Loss: 1.6840\n",
      "Epoch [   9/500], Step [   1/1], Loss: 1.6560 Validation Loss: 1.6820\n",
      "Epoch [  10/500], Step [   1/1], Loss: 1.6503 Validation Loss: 1.6808\n",
      "Epoch [  11/500], Step [   1/1], Loss: 1.6458 Validation Loss: 1.6801\n",
      "Epoch [  12/500], Step [   1/1], Loss: 1.6420 Validation Loss: 1.6797\n",
      "Epoch [  13/500], Step [   1/1], Loss: 1.6385 Validation Loss: 1.6794\n",
      "Epoch [  14/500], Step [   1/1], Loss: 1.6355 Validation Loss: 1.6788\n",
      "Epoch [  15/500], Step [   1/1], Loss: 1.6329 Validation Loss: 1.6777\n",
      "Epoch [  16/500], Step [   1/1], Loss: 1.6305 Validation Loss: 1.6763\n",
      "Epoch [  17/500], Step [   1/1], Loss: 1.6282 Validation Loss: 1.6743\n",
      "Epoch [  18/500], Step [   1/1], Loss: 1.6256 Validation Loss: 1.6719\n",
      "Epoch [  19/500], Step [   1/1], Loss: 1.6228 Validation Loss: 1.6695\n",
      "Epoch [  20/500], Step [   1/1], Loss: 1.6199 Validation Loss: 1.6630\n",
      "Epoch [  21/500], Step [   1/1], Loss: 1.6148 Validation Loss: 1.6548\n",
      "Epoch [  22/500], Step [   1/1], Loss: 1.6092 Validation Loss: 1.6482\n",
      "Epoch [  23/500], Step [   1/1], Loss: 1.6045 Validation Loss: 1.6429\n",
      "Epoch [  24/500], Step [   1/1], Loss: 1.6004 Validation Loss: 1.6378\n",
      "Epoch [  25/500], Step [   1/1], Loss: 1.5964 Validation Loss: 1.6331\n",
      "Epoch [  26/500], Step [   1/1], Loss: 1.5926 Validation Loss: 1.6288\n",
      "Epoch [  27/500], Step [   1/1], Loss: 1.5891 Validation Loss: 1.6250\n",
      "Epoch [  28/500], Step [   1/1], Loss: 1.5856 Validation Loss: 1.6213\n",
      "Epoch [  29/500], Step [   1/1], Loss: 1.5823 Validation Loss: 1.6177\n",
      "Epoch [  30/500], Step [   1/1], Loss: 1.5792 Validation Loss: 1.6143\n",
      "Epoch [  31/500], Step [   1/1], Loss: 1.5762 Validation Loss: 1.6111\n",
      "Epoch [  32/500], Step [   1/1], Loss: 1.5733 Validation Loss: 1.6081\n",
      "Epoch [  33/500], Step [   1/1], Loss: 1.5705 Validation Loss: 1.6053\n",
      "Epoch [  34/500], Step [   1/1], Loss: 1.5678 Validation Loss: 1.6027\n",
      "Epoch [  35/500], Step [   1/1], Loss: 1.5651 Validation Loss: 1.6001\n",
      "Epoch [  36/500], Step [   1/1], Loss: 1.5625 Validation Loss: 1.5977\n",
      "Epoch [  37/500], Step [   1/1], Loss: 1.5600 Validation Loss: 1.5954\n",
      "Epoch [  38/500], Step [   1/1], Loss: 1.5576 Validation Loss: 1.5933\n",
      "Epoch [  39/500], Step [   1/1], Loss: 1.5551 Validation Loss: 1.5912\n",
      "Epoch [  40/500], Step [   1/1], Loss: 1.5528 Validation Loss: 1.5893\n",
      "Epoch [  41/500], Step [   1/1], Loss: 1.5504 Validation Loss: 1.5873\n",
      "Epoch [  42/500], Step [   1/1], Loss: 1.5481 Validation Loss: 1.5854\n",
      "Epoch [  43/500], Step [   1/1], Loss: 1.5457 Validation Loss: 1.5836\n",
      "Epoch [  44/500], Step [   1/1], Loss: 1.5434 Validation Loss: 1.5819\n",
      "Epoch [  45/500], Step [   1/1], Loss: 1.5411 Validation Loss: 1.5800\n",
      "Epoch [  46/500], Step [   1/1], Loss: 1.5389 Validation Loss: 1.5782\n",
      "Epoch [  47/500], Step [   1/1], Loss: 1.5366 Validation Loss: 1.5764\n",
      "Epoch [  48/500], Step [   1/1], Loss: 1.5344 Validation Loss: 1.5747\n",
      "Epoch [  49/500], Step [   1/1], Loss: 1.5321 Validation Loss: 1.5728\n",
      "Epoch [  50/500], Step [   1/1], Loss: 1.5299 Validation Loss: 1.5711\n",
      "Epoch [  51/500], Step [   1/1], Loss: 1.5276 Validation Loss: 1.5694\n",
      "Epoch [  52/500], Step [   1/1], Loss: 1.5253 Validation Loss: 1.5677\n",
      "Epoch [  53/500], Step [   1/1], Loss: 1.5231 Validation Loss: 1.5660\n",
      "Epoch [  54/500], Step [   1/1], Loss: 1.5208 Validation Loss: 1.5641\n",
      "Epoch [  55/500], Step [   1/1], Loss: 1.5186 Validation Loss: 1.5623\n",
      "Epoch [  56/500], Step [   1/1], Loss: 1.5164 Validation Loss: 1.5606\n",
      "Epoch [  57/500], Step [   1/1], Loss: 1.5142 Validation Loss: 1.5587\n",
      "Epoch [  58/500], Step [   1/1], Loss: 1.5120 Validation Loss: 1.5570\n",
      "Epoch [  59/500], Step [   1/1], Loss: 1.5097 Validation Loss: 1.5552\n",
      "Epoch [  60/500], Step [   1/1], Loss: 1.5075 Validation Loss: 1.5533\n",
      "Epoch [  61/500], Step [   1/1], Loss: 1.5053 Validation Loss: 1.5515\n",
      "Epoch [  62/500], Step [   1/1], Loss: 1.5031 Validation Loss: 1.5498\n",
      "Epoch [  63/500], Step [   1/1], Loss: 1.5009 Validation Loss: 1.5480\n",
      "Epoch [  64/500], Step [   1/1], Loss: 1.4987 Validation Loss: 1.5463\n",
      "Epoch [  65/500], Step [   1/1], Loss: 1.4965 Validation Loss: 1.5444\n",
      "Epoch [  66/500], Step [   1/1], Loss: 1.4943 Validation Loss: 1.5428\n",
      "Epoch [  67/500], Step [   1/1], Loss: 1.4921 Validation Loss: 1.5412\n",
      "Epoch [  68/500], Step [   1/1], Loss: 1.4899 Validation Loss: 1.5395\n",
      "Epoch [  69/500], Step [   1/1], Loss: 1.4877 Validation Loss: 1.5378\n",
      "Epoch [  70/500], Step [   1/1], Loss: 1.4854 Validation Loss: 1.5359\n",
      "Epoch [  71/500], Step [   1/1], Loss: 1.4832 Validation Loss: 1.5342\n",
      "Epoch [  72/500], Step [   1/1], Loss: 1.4809 Validation Loss: 1.5324\n",
      "Epoch [  73/500], Step [   1/1], Loss: 1.4787 Validation Loss: 1.5306\n",
      "Epoch [  74/500], Step [   1/1], Loss: 1.4764 Validation Loss: 1.5288\n",
      "Epoch [  75/500], Step [   1/1], Loss: 1.4742 Validation Loss: 1.5271\n",
      "Epoch [  76/500], Step [   1/1], Loss: 1.4719 Validation Loss: 1.5252\n",
      "Epoch [  77/500], Step [   1/1], Loss: 1.4697 Validation Loss: 1.5234\n",
      "Epoch [  78/500], Step [   1/1], Loss: 1.4675 Validation Loss: 1.5217\n",
      "Epoch [  79/500], Step [   1/1], Loss: 1.4653 Validation Loss: 1.5202\n",
      "Epoch [  80/500], Step [   1/1], Loss: 1.4631 Validation Loss: 1.5185\n",
      "Epoch [  81/500], Step [   1/1], Loss: 1.4610 Validation Loss: 1.5167\n",
      "Epoch [  82/500], Step [   1/1], Loss: 1.4587 Validation Loss: 1.5149\n",
      "Epoch [  83/500], Step [   1/1], Loss: 1.4565 Validation Loss: 1.5133\n",
      "Epoch [  84/500], Step [   1/1], Loss: 1.4544 Validation Loss: 1.5117\n",
      "Epoch [  85/500], Step [   1/1], Loss: 1.4522 Validation Loss: 1.5101\n",
      "Epoch [  86/500], Step [   1/1], Loss: 1.4500 Validation Loss: 1.5088\n",
      "Epoch [  87/500], Step [   1/1], Loss: 1.4477 Validation Loss: 1.5076\n",
      "Epoch [  88/500], Step [   1/1], Loss: 1.4455 Validation Loss: 1.5065\n",
      "Epoch [  89/500], Step [   1/1], Loss: 1.4434 Validation Loss: 1.5052\n",
      "Epoch [  90/500], Step [   1/1], Loss: 1.4413 Validation Loss: 1.5034\n",
      "Epoch [  91/500], Step [   1/1], Loss: 1.4390 Validation Loss: 1.5023\n",
      "Epoch [  92/500], Step [   1/1], Loss: 1.4368 Validation Loss: 1.5007\n",
      "Epoch [  93/500], Step [   1/1], Loss: 1.4341 Validation Loss: 1.4986\n",
      "Epoch [  94/500], Step [   1/1], Loss: 1.4309 Validation Loss: 1.4963\n",
      "Epoch [  95/500], Step [   1/1], Loss: 1.4271 Validation Loss: 1.4931\n",
      "Epoch [  96/500], Step [   1/1], Loss: 1.4225 Validation Loss: 1.4905\n",
      "Epoch [  97/500], Step [   1/1], Loss: 1.4182 Validation Loss: 1.4883\n",
      "Epoch [  98/500], Step [   1/1], Loss: 1.4143 Validation Loss: 1.4862\n",
      "Epoch [  99/500], Step [   1/1], Loss: 1.4105 Validation Loss: 1.4842\n",
      "Epoch [ 100/500], Step [   1/1], Loss: 1.4069 Validation Loss: 1.4825\n",
      "Epoch [ 101/500], Step [   1/1], Loss: 1.4033 Validation Loss: 1.4814\n",
      "Epoch [ 102/500], Step [   1/1], Loss: 1.4008 Validation Loss: 1.4803\n",
      "Epoch [ 103/500], Step [   1/1], Loss: 1.3983 Validation Loss: 1.4792\n",
      "Epoch [ 104/500], Step [   1/1], Loss: 1.3959 Validation Loss: 1.4781\n",
      "Epoch [ 105/500], Step [   1/1], Loss: 1.3935 Validation Loss: 1.4771\n",
      "Epoch [ 106/500], Step [   1/1], Loss: 1.3912 Validation Loss: 1.4760\n",
      "Epoch [ 107/500], Step [   1/1], Loss: 1.3889 Validation Loss: 1.4750\n",
      "Epoch [ 108/500], Step [   1/1], Loss: 1.3867 Validation Loss: 1.4740\n",
      "Epoch [ 109/500], Step [   1/1], Loss: 1.3844 Validation Loss: 1.4728\n",
      "Epoch [ 110/500], Step [   1/1], Loss: 1.3823 Validation Loss: 1.4718\n",
      "Epoch [ 111/500], Step [   1/1], Loss: 1.3801 Validation Loss: 1.4710\n",
      "Epoch [ 112/500], Step [   1/1], Loss: 1.3780 Validation Loss: 1.4701\n",
      "Epoch [ 113/500], Step [   1/1], Loss: 1.3758 Validation Loss: 1.4693\n",
      "Epoch [ 114/500], Step [   1/1], Loss: 1.3737 Validation Loss: 1.4686\n",
      "Epoch [ 115/500], Step [   1/1], Loss: 1.3717 Validation Loss: 1.4679\n",
      "Epoch [ 116/500], Step [   1/1], Loss: 1.3696 Validation Loss: 1.4672\n",
      "Epoch [ 117/500], Step [   1/1], Loss: 1.3675 Validation Loss: 1.4665\n",
      "Epoch [ 118/500], Step [   1/1], Loss: 1.3655 Validation Loss: 1.4657\n",
      "Epoch [ 119/500], Step [   1/1], Loss: 1.3635 Validation Loss: 1.4651\n",
      "Epoch [ 120/500], Step [   1/1], Loss: 1.3616 Validation Loss: 1.4644\n",
      "Epoch [ 121/500], Step [   1/1], Loss: 1.3596 Validation Loss: 1.4639\n",
      "Epoch [ 122/500], Step [   1/1], Loss: 1.3584 Validation Loss: 1.4635\n",
      "Epoch [ 123/500], Step [   1/1], Loss: 1.3572 Validation Loss: 1.4632\n",
      "Epoch [ 124/500], Step [   1/1], Loss: 1.3559 Validation Loss: 1.4628\n",
      "Epoch [ 125/500], Step [   1/1], Loss: 1.3547 Validation Loss: 1.4624\n",
      "Epoch [ 126/500], Step [   1/1], Loss: 1.3535 Validation Loss: 1.4621\n",
      "Epoch [ 127/500], Step [   1/1], Loss: 1.3522 Validation Loss: 1.4617\n",
      "Epoch [ 128/500], Step [   1/1], Loss: 1.3510 Validation Loss: 1.4613\n",
      "Epoch [ 129/500], Step [   1/1], Loss: 1.3499 Validation Loss: 1.4609\n",
      "Epoch [ 130/500], Step [   1/1], Loss: 1.3487 Validation Loss: 1.4606\n",
      "Epoch [ 131/500], Step [   1/1], Loss: 1.3475 Validation Loss: 1.4602\n",
      "Epoch [ 132/500], Step [   1/1], Loss: 1.3463 Validation Loss: 1.4599\n",
      "Epoch [ 133/500], Step [   1/1], Loss: 1.3452 Validation Loss: 1.4595\n",
      "Epoch [ 134/500], Step [   1/1], Loss: 1.3440 Validation Loss: 1.4592\n",
      "Epoch [ 135/500], Step [   1/1], Loss: 1.3429 Validation Loss: 1.4588\n",
      "Epoch [ 136/500], Step [   1/1], Loss: 1.3418 Validation Loss: 1.4588\n",
      "Epoch [ 137/500], Step [   1/1], Loss: 1.3407 Validation Loss: 1.4586\n",
      "Epoch [ 138/500], Step [   1/1], Loss: 1.3396 Validation Loss: 1.4584\n",
      "Epoch [ 139/500], Step [   1/1], Loss: 1.3385 Validation Loss: 1.4583\n",
      "Epoch [ 140/500], Step [   1/1], Loss: 1.3374 Validation Loss: 1.4580\n",
      "Epoch [ 141/500], Step [   1/1], Loss: 1.3363 Validation Loss: 1.4578\n",
      "Epoch [ 142/500], Step [   1/1], Loss: 1.3352 Validation Loss: 1.4577\n",
      "Epoch [ 143/500], Step [   1/1], Loss: 1.3342 Validation Loss: 1.4575\n",
      "Epoch [ 144/500], Step [   1/1], Loss: 1.3331 Validation Loss: 1.4575\n",
      "Epoch [ 145/500], Step [   1/1], Loss: 1.3321 Validation Loss: 1.4572\n",
      "Epoch [ 146/500], Step [   1/1], Loss: 1.3311 Validation Loss: 1.4571\n",
      "Epoch [ 147/500], Step [   1/1], Loss: 1.3300 Validation Loss: 1.4570\n",
      "Epoch [ 148/500], Step [   1/1], Loss: 1.3290 Validation Loss: 1.4569\n",
      "Epoch [ 149/500], Step [   1/1], Loss: 1.3280 Validation Loss: 1.4567\n",
      "Epoch [ 150/500], Step [   1/1], Loss: 1.3270 Validation Loss: 1.4566\n",
      "Epoch [ 151/500], Step [   1/1], Loss: 1.3260 Validation Loss: 1.4563\n",
      "Epoch [ 152/500], Step [   1/1], Loss: 1.3250 Validation Loss: 1.4561\n",
      "Epoch [ 153/500], Step [   1/1], Loss: 1.3241 Validation Loss: 1.4559\n",
      "Epoch [ 154/500], Step [   1/1], Loss: 1.3231 Validation Loss: 1.4557\n",
      "Epoch [ 155/500], Step [   1/1], Loss: 1.3221 Validation Loss: 1.4554\n",
      "Epoch [ 156/500], Step [   1/1], Loss: 1.3212 Validation Loss: 1.4552\n",
      "Epoch [ 157/500], Step [   1/1], Loss: 1.3202 Validation Loss: 1.4550\n",
      "Epoch [ 158/500], Step [   1/1], Loss: 1.3192 Validation Loss: 1.4547\n",
      "Epoch [ 159/500], Step [   1/1], Loss: 1.3183 Validation Loss: 1.4545\n",
      "Epoch [ 160/500], Step [   1/1], Loss: 1.3173 Validation Loss: 1.4543\n",
      "Epoch [ 161/500], Step [   1/1], Loss: 1.3164 Validation Loss: 1.4541\n",
      "Epoch [ 162/500], Step [   1/1], Loss: 1.3155 Validation Loss: 1.4539\n",
      "Epoch [ 163/500], Step [   1/1], Loss: 1.3145 Validation Loss: 1.4537\n",
      "Epoch [ 164/500], Step [   1/1], Loss: 1.3136 Validation Loss: 1.4535\n",
      "Epoch [ 165/500], Step [   1/1], Loss: 1.3127 Validation Loss: 1.4533\n",
      "Epoch [ 166/500], Step [   1/1], Loss: 1.3118 Validation Loss: 1.4531\n",
      "Epoch [ 167/500], Step [   1/1], Loss: 1.3109 Validation Loss: 1.4529\n",
      "Epoch [ 168/500], Step [   1/1], Loss: 1.3100 Validation Loss: 1.4526\n",
      "Epoch [ 169/500], Step [   1/1], Loss: 1.3091 Validation Loss: 1.4524\n",
      "Epoch [ 170/500], Step [   1/1], Loss: 1.3082 Validation Loss: 1.4522\n",
      "Epoch [ 171/500], Step [   1/1], Loss: 1.3073 Validation Loss: 1.4520\n",
      "Epoch [ 172/500], Step [   1/1], Loss: 1.3064 Validation Loss: 1.4518\n",
      "Epoch [ 173/500], Step [   1/1], Loss: 1.3055 Validation Loss: 1.4519\n",
      "Epoch [ 174/500], Step [   1/1], Loss: 1.3046 Validation Loss: 1.4519\n",
      "Epoch [ 175/500], Step [   1/1], Loss: 1.3036 Validation Loss: 1.4518\n",
      "Epoch [ 176/500], Step [   1/1], Loss: 1.3026 Validation Loss: 1.4518\n",
      "Epoch [ 177/500], Step [   1/1], Loss: 1.3016 Validation Loss: 1.4516\n",
      "Epoch [ 178/500], Step [   1/1], Loss: 1.3007 Validation Loss: 1.4515\n",
      "Epoch [ 179/500], Step [   1/1], Loss: 1.2997 Validation Loss: 1.4514\n",
      "Epoch [ 180/500], Step [   1/1], Loss: 1.2987 Validation Loss: 1.4513\n",
      "Epoch [ 181/500], Step [   1/1], Loss: 1.2977 Validation Loss: 1.4511\n",
      "Epoch [ 182/500], Step [   1/1], Loss: 1.2968 Validation Loss: 1.4510\n",
      "Epoch [ 183/500], Step [   1/1], Loss: 1.2958 Validation Loss: 1.4508\n",
      "Epoch [ 184/500], Step [   1/1], Loss: 1.2948 Validation Loss: 1.4507\n",
      "Epoch [ 185/500], Step [   1/1], Loss: 1.2939 Validation Loss: 1.4505\n",
      "Epoch [ 186/500], Step [   1/1], Loss: 1.2929 Validation Loss: 1.4504\n",
      "Epoch [ 187/500], Step [   1/1], Loss: 1.2920 Validation Loss: 1.4502\n",
      "Epoch [ 188/500], Step [   1/1], Loss: 1.2910 Validation Loss: 1.4500\n",
      "Epoch [ 189/500], Step [   1/1], Loss: 1.2901 Validation Loss: 1.4499\n",
      "Epoch [ 190/500], Step [   1/1], Loss: 1.2892 Validation Loss: 1.4498\n",
      "Epoch [ 191/500], Step [   1/1], Loss: 1.2882 Validation Loss: 1.4496\n",
      "Epoch [ 192/500], Step [   1/1], Loss: 1.2873 Validation Loss: 1.4495\n",
      "Epoch [ 193/500], Step [   1/1], Loss: 1.2864 Validation Loss: 1.4494\n",
      "Epoch [ 194/500], Step [   1/1], Loss: 1.2853 Validation Loss: 1.4494\n",
      "Epoch [ 195/500], Step [   1/1], Loss: 1.2842 Validation Loss: 1.4491\n",
      "Epoch [ 196/500], Step [   1/1], Loss: 1.2831 Validation Loss: 1.4487\n",
      "Epoch [ 197/500], Step [   1/1], Loss: 1.2820 Validation Loss: 1.4482\n",
      "Epoch [ 198/500], Step [   1/1], Loss: 1.2803 Validation Loss: 1.4476\n",
      "Epoch [ 199/500], Step [   1/1], Loss: 1.2784 Validation Loss: 1.4470\n",
      "Epoch [ 200/500], Step [   1/1], Loss: 1.2763 Validation Loss: 1.4461\n",
      "Epoch [ 201/500], Step [   1/1], Loss: 1.2732 Validation Loss: 1.4457\n",
      "Epoch [ 202/500], Step [   1/1], Loss: 1.2708 Validation Loss: 1.4447\n",
      "Epoch [ 203/500], Step [   1/1], Loss: 1.2685 Validation Loss: 1.4428\n",
      "Epoch [ 204/500], Step [   1/1], Loss: 1.2663 Validation Loss: 1.4401\n",
      "Epoch [ 205/500], Step [   1/1], Loss: 1.2640 Validation Loss: 1.4361\n",
      "Epoch [ 206/500], Step [   1/1], Loss: 1.2611 Validation Loss: 1.4316\n",
      "Epoch [ 207/500], Step [   1/1], Loss: 1.2578 Validation Loss: 1.4273\n",
      "Epoch [ 208/500], Step [   1/1], Loss: 1.2542 Validation Loss: 1.4226\n",
      "Epoch [ 209/500], Step [   1/1], Loss: 1.2503 Validation Loss: 1.4181\n",
      "Epoch [ 210/500], Step [   1/1], Loss: 1.2466 Validation Loss: 1.4139\n",
      "Epoch [ 211/500], Step [   1/1], Loss: 1.2430 Validation Loss: 1.4098\n",
      "Epoch [ 212/500], Step [   1/1], Loss: 1.2395 Validation Loss: 1.4057\n",
      "Epoch [ 213/500], Step [   1/1], Loss: 1.2361 Validation Loss: 1.4018\n",
      "Epoch [ 214/500], Step [   1/1], Loss: 1.2327 Validation Loss: 1.3982\n",
      "Epoch [ 215/500], Step [   1/1], Loss: 1.2296 Validation Loss: 1.3950\n",
      "Epoch [ 216/500], Step [   1/1], Loss: 1.2267 Validation Loss: 1.3918\n",
      "Epoch [ 217/500], Step [   1/1], Loss: 1.2239 Validation Loss: 1.3888\n",
      "Epoch [ 218/500], Step [   1/1], Loss: 1.2212 Validation Loss: 1.3858\n",
      "Epoch [ 219/500], Step [   1/1], Loss: 1.2184 Validation Loss: 1.3829\n",
      "Epoch [ 220/500], Step [   1/1], Loss: 1.2158 Validation Loss: 1.3800\n",
      "Epoch [ 221/500], Step [   1/1], Loss: 1.2131 Validation Loss: 1.3773\n",
      "Epoch [ 222/500], Step [   1/1], Loss: 1.2106 Validation Loss: 1.3747\n",
      "Epoch [ 223/500], Step [   1/1], Loss: 1.2080 Validation Loss: 1.3721\n",
      "Epoch [ 224/500], Step [   1/1], Loss: 1.2055 Validation Loss: 1.3695\n",
      "Epoch [ 225/500], Step [   1/1], Loss: 1.2030 Validation Loss: 1.3671\n",
      "Epoch [ 226/500], Step [   1/1], Loss: 1.2006 Validation Loss: 1.3648\n",
      "Epoch [ 227/500], Step [   1/1], Loss: 1.1982 Validation Loss: 1.3625\n",
      "Epoch [ 228/500], Step [   1/1], Loss: 1.1959 Validation Loss: 1.3604\n",
      "Epoch [ 229/500], Step [   1/1], Loss: 1.1936 Validation Loss: 1.3583\n",
      "Epoch [ 230/500], Step [   1/1], Loss: 1.1913 Validation Loss: 1.3564\n",
      "Epoch [ 231/500], Step [   1/1], Loss: 1.1890 Validation Loss: 1.3545\n",
      "Epoch [ 232/500], Step [   1/1], Loss: 1.1868 Validation Loss: 1.3525\n",
      "Epoch [ 233/500], Step [   1/1], Loss: 1.1847 Validation Loss: 1.3506\n",
      "Epoch [ 234/500], Step [   1/1], Loss: 1.1825 Validation Loss: 1.3487\n",
      "Epoch [ 235/500], Step [   1/1], Loss: 1.1804 Validation Loss: 1.3470\n",
      "Epoch [ 236/500], Step [   1/1], Loss: 1.1783 Validation Loss: 1.3453\n",
      "Epoch [ 237/500], Step [   1/1], Loss: 1.1762 Validation Loss: 1.3436\n",
      "Epoch [ 238/500], Step [   1/1], Loss: 1.1741 Validation Loss: 1.3420\n",
      "Epoch [ 239/500], Step [   1/1], Loss: 1.1721 Validation Loss: 1.3405\n",
      "Epoch [ 240/500], Step [   1/1], Loss: 1.1701 Validation Loss: 1.3390\n",
      "Epoch [ 241/500], Step [   1/1], Loss: 1.1681 Validation Loss: 1.3380\n",
      "Epoch [ 242/500], Step [   1/1], Loss: 1.1668 Validation Loss: 1.3369\n",
      "Epoch [ 243/500], Step [   1/1], Loss: 1.1654 Validation Loss: 1.3359\n",
      "Epoch [ 244/500], Step [   1/1], Loss: 1.1641 Validation Loss: 1.3350\n",
      "Epoch [ 245/500], Step [   1/1], Loss: 1.1627 Validation Loss: 1.3340\n",
      "Epoch [ 246/500], Step [   1/1], Loss: 1.1614 Validation Loss: 1.3331\n",
      "Epoch [ 247/500], Step [   1/1], Loss: 1.1601 Validation Loss: 1.3323\n",
      "Epoch [ 248/500], Step [   1/1], Loss: 1.1589 Validation Loss: 1.3314\n",
      "Epoch [ 249/500], Step [   1/1], Loss: 1.1576 Validation Loss: 1.3306\n",
      "Epoch [ 250/500], Step [   1/1], Loss: 1.1564 Validation Loss: 1.3298\n",
      "Epoch [ 251/500], Step [   1/1], Loss: 1.1551 Validation Loss: 1.3291\n",
      "Epoch [ 252/500], Step [   1/1], Loss: 1.1539 Validation Loss: 1.3283\n",
      "Epoch [ 253/500], Step [   1/1], Loss: 1.1527 Validation Loss: 1.3276\n",
      "Epoch [ 254/500], Step [   1/1], Loss: 1.1515 Validation Loss: 1.3268\n",
      "Epoch [ 255/500], Step [   1/1], Loss: 1.1503 Validation Loss: 1.3261\n",
      "Epoch [ 256/500], Step [   1/1], Loss: 1.1491 Validation Loss: 1.3253\n",
      "Epoch [ 257/500], Step [   1/1], Loss: 1.1480 Validation Loss: 1.3245\n",
      "Epoch [ 258/500], Step [   1/1], Loss: 1.1468 Validation Loss: 1.3237\n",
      "Epoch [ 259/500], Step [   1/1], Loss: 1.1457 Validation Loss: 1.3230\n",
      "Epoch [ 260/500], Step [   1/1], Loss: 1.1445 Validation Loss: 1.3224\n",
      "Epoch [ 261/500], Step [   1/1], Loss: 1.1434 Validation Loss: 1.3217\n",
      "Epoch [ 262/500], Step [   1/1], Loss: 1.1423 Validation Loss: 1.3211\n",
      "Epoch [ 263/500], Step [   1/1], Loss: 1.1412 Validation Loss: 1.3205\n",
      "Epoch [ 264/500], Step [   1/1], Loss: 1.1401 Validation Loss: 1.3199\n",
      "Epoch [ 265/500], Step [   1/1], Loss: 1.1390 Validation Loss: 1.3194\n",
      "Epoch [ 266/500], Step [   1/1], Loss: 1.1379 Validation Loss: 1.3189\n",
      "Epoch [ 267/500], Step [   1/1], Loss: 1.1368 Validation Loss: 1.3184\n",
      "Epoch [ 268/500], Step [   1/1], Loss: 1.1357 Validation Loss: 1.3178\n",
      "Epoch [ 269/500], Step [   1/1], Loss: 1.1347 Validation Loss: 1.3172\n",
      "Epoch [ 270/500], Step [   1/1], Loss: 1.1336 Validation Loss: 1.3167\n",
      "Epoch [ 271/500], Step [   1/1], Loss: 1.1326 Validation Loss: 1.3162\n",
      "Epoch [ 272/500], Step [   1/1], Loss: 1.1315 Validation Loss: 1.3157\n",
      "Epoch [ 273/500], Step [   1/1], Loss: 1.1305 Validation Loss: 1.3152\n",
      "Epoch [ 274/500], Step [   1/1], Loss: 1.1294 Validation Loss: 1.3147\n",
      "Epoch [ 275/500], Step [   1/1], Loss: 1.1284 Validation Loss: 1.3143\n",
      "Epoch [ 276/500], Step [   1/1], Loss: 1.1274 Validation Loss: 1.3138\n",
      "Epoch [ 277/500], Step [   1/1], Loss: 1.1264 Validation Loss: 1.3133\n",
      "Epoch [ 278/500], Step [   1/1], Loss: 1.1253 Validation Loss: 1.3129\n",
      "Epoch [ 279/500], Step [   1/1], Loss: 1.1243 Validation Loss: 1.3125\n",
      "Epoch [ 280/500], Step [   1/1], Loss: 1.1233 Validation Loss: 1.3120\n",
      "Epoch [ 281/500], Step [   1/1], Loss: 1.1223 Validation Loss: 1.3116\n",
      "Epoch [ 282/500], Step [   1/1], Loss: 1.1213 Validation Loss: 1.3112\n",
      "Epoch [ 283/500], Step [   1/1], Loss: 1.1203 Validation Loss: 1.3108\n",
      "Epoch [ 284/500], Step [   1/1], Loss: 1.1193 Validation Loss: 1.3104\n",
      "Epoch [ 285/500], Step [   1/1], Loss: 1.1183 Validation Loss: 1.3100\n",
      "Epoch [ 286/500], Step [   1/1], Loss: 1.1173 Validation Loss: 1.3096\n",
      "Epoch [ 287/500], Step [   1/1], Loss: 1.1163 Validation Loss: 1.3092\n",
      "Epoch [ 288/500], Step [   1/1], Loss: 1.1153 Validation Loss: 1.3088\n",
      "Epoch [ 289/500], Step [   1/1], Loss: 1.1143 Validation Loss: 1.3083\n",
      "Epoch [ 290/500], Step [   1/1], Loss: 1.1133 Validation Loss: 1.3080\n",
      "Epoch [ 291/500], Step [   1/1], Loss: 1.1124 Validation Loss: 1.3076\n",
      "Epoch [ 292/500], Step [   1/1], Loss: 1.1114 Validation Loss: 1.3072\n",
      "Epoch [ 293/500], Step [   1/1], Loss: 1.1104 Validation Loss: 1.3069\n",
      "Epoch [ 294/500], Step [   1/1], Loss: 1.1095 Validation Loss: 1.3065\n",
      "Epoch [ 295/500], Step [   1/1], Loss: 1.1085 Validation Loss: 1.3061\n",
      "Epoch [ 296/500], Step [   1/1], Loss: 1.1075 Validation Loss: 1.3058\n",
      "Epoch [ 297/500], Step [   1/1], Loss: 1.1066 Validation Loss: 1.3054\n",
      "Epoch [ 298/500], Step [   1/1], Loss: 1.1056 Validation Loss: 1.3050\n",
      "Epoch [ 299/500], Step [   1/1], Loss: 1.1047 Validation Loss: 1.3047\n",
      "Epoch [ 300/500], Step [   1/1], Loss: 1.1037 Validation Loss: 1.3044\n",
      "Epoch [ 301/500], Step [   1/1], Loss: 1.1028 Validation Loss: 1.3041\n",
      "Epoch [ 302/500], Step [   1/1], Loss: 1.1021 Validation Loss: 1.3038\n",
      "Epoch [ 303/500], Step [   1/1], Loss: 1.1014 Validation Loss: 1.3035\n",
      "Epoch [ 304/500], Step [   1/1], Loss: 1.1006 Validation Loss: 1.3032\n",
      "Epoch [ 305/500], Step [   1/1], Loss: 1.0999 Validation Loss: 1.3029\n",
      "Epoch [ 306/500], Step [   1/1], Loss: 1.0992 Validation Loss: 1.3025\n",
      "Epoch [ 307/500], Step [   1/1], Loss: 1.0985 Validation Loss: 1.3022\n",
      "Epoch [ 308/500], Step [   1/1], Loss: 1.0978 Validation Loss: 1.3019\n",
      "Epoch [ 309/500], Step [   1/1], Loss: 1.0971 Validation Loss: 1.3016\n",
      "Epoch [ 310/500], Step [   1/1], Loss: 1.0963 Validation Loss: 1.3013\n",
      "Epoch [ 311/500], Step [   1/1], Loss: 1.0956 Validation Loss: 1.3010\n",
      "Epoch [ 312/500], Step [   1/1], Loss: 1.0949 Validation Loss: 1.3007\n",
      "Epoch [ 313/500], Step [   1/1], Loss: 1.0942 Validation Loss: 1.3004\n",
      "Epoch [ 314/500], Step [   1/1], Loss: 1.0935 Validation Loss: 1.3001\n",
      "Epoch [ 315/500], Step [   1/1], Loss: 1.0928 Validation Loss: 1.2998\n",
      "Epoch [ 316/500], Step [   1/1], Loss: 1.0921 Validation Loss: 1.2995\n",
      "Epoch [ 317/500], Step [   1/1], Loss: 1.0914 Validation Loss: 1.2993\n",
      "Epoch [ 318/500], Step [   1/1], Loss: 1.0907 Validation Loss: 1.2990\n",
      "Epoch [ 319/500], Step [   1/1], Loss: 1.0900 Validation Loss: 1.2987\n",
      "Epoch [ 320/500], Step [   1/1], Loss: 1.0893 Validation Loss: 1.2985\n",
      "Epoch [ 321/500], Step [   1/1], Loss: 1.0886 Validation Loss: 1.2982\n",
      "Epoch [ 322/500], Step [   1/1], Loss: 1.0879 Validation Loss: 1.2980\n",
      "Epoch [ 323/500], Step [   1/1], Loss: 1.0872 Validation Loss: 1.2977\n",
      "Epoch [ 324/500], Step [   1/1], Loss: 1.0865 Validation Loss: 1.2975\n",
      "Epoch [ 325/500], Step [   1/1], Loss: 1.0858 Validation Loss: 1.2973\n",
      "Epoch [ 326/500], Step [   1/1], Loss: 1.0851 Validation Loss: 1.2970\n",
      "Epoch [ 327/500], Step [   1/1], Loss: 1.0845 Validation Loss: 1.2968\n",
      "Epoch [ 328/500], Step [   1/1], Loss: 1.0838 Validation Loss: 1.2965\n",
      "Epoch [ 329/500], Step [   1/1], Loss: 1.0831 Validation Loss: 1.2963\n",
      "Epoch [ 330/500], Step [   1/1], Loss: 1.0824 Validation Loss: 1.2961\n",
      "Epoch [ 331/500], Step [   1/1], Loss: 1.0817 Validation Loss: 1.2958\n",
      "Epoch [ 332/500], Step [   1/1], Loss: 1.0810 Validation Loss: 1.2956\n",
      "Epoch [ 333/500], Step [   1/1], Loss: 1.0804 Validation Loss: 1.2953\n",
      "Epoch [ 334/500], Step [   1/1], Loss: 1.0797 Validation Loss: 1.2951\n",
      "Epoch [ 335/500], Step [   1/1], Loss: 1.0790 Validation Loss: 1.2949\n",
      "Epoch [ 336/500], Step [   1/1], Loss: 1.0783 Validation Loss: 1.2946\n",
      "Epoch [ 337/500], Step [   1/1], Loss: 1.0776 Validation Loss: 1.2944\n",
      "Epoch [ 338/500], Step [   1/1], Loss: 1.0770 Validation Loss: 1.2942\n",
      "Epoch [ 339/500], Step [   1/1], Loss: 1.0763 Validation Loss: 1.2939\n",
      "Epoch [ 340/500], Step [   1/1], Loss: 1.0756 Validation Loss: 1.2937\n",
      "Epoch [ 341/500], Step [   1/1], Loss: 1.0750 Validation Loss: 1.2935\n",
      "Epoch [ 342/500], Step [   1/1], Loss: 1.0743 Validation Loss: 1.2932\n",
      "Epoch [ 343/500], Step [   1/1], Loss: 1.0736 Validation Loss: 1.2930\n",
      "Epoch [ 344/500], Step [   1/1], Loss: 1.0730 Validation Loss: 1.2928\n",
      "Epoch [ 345/500], Step [   1/1], Loss: 1.0723 Validation Loss: 1.2925\n",
      "Epoch [ 346/500], Step [   1/1], Loss: 1.0716 Validation Loss: 1.2923\n",
      "Epoch [ 347/500], Step [   1/1], Loss: 1.0710 Validation Loss: 1.2921\n",
      "Epoch [ 348/500], Step [   1/1], Loss: 1.0703 Validation Loss: 1.2919\n",
      "Epoch [ 349/500], Step [   1/1], Loss: 1.0696 Validation Loss: 1.2916\n",
      "Epoch [ 350/500], Step [   1/1], Loss: 1.0690 Validation Loss: 1.2914\n",
      "Epoch [ 351/500], Step [   1/1], Loss: 1.0683 Validation Loss: 1.2912\n",
      "Epoch [ 352/500], Step [   1/1], Loss: 1.0677 Validation Loss: 1.2910\n",
      "Epoch [ 353/500], Step [   1/1], Loss: 1.0670 Validation Loss: 1.2907\n",
      "Epoch [ 354/500], Step [   1/1], Loss: 1.0664 Validation Loss: 1.2905\n",
      "Epoch [ 355/500], Step [   1/1], Loss: 1.0657 Validation Loss: 1.2902\n",
      "Epoch [ 356/500], Step [   1/1], Loss: 1.0651 Validation Loss: 1.2900\n",
      "Epoch [ 357/500], Step [   1/1], Loss: 1.0644 Validation Loss: 1.2898\n",
      "Epoch [ 358/500], Step [   1/1], Loss: 1.0638 Validation Loss: 1.2896\n",
      "Epoch [ 359/500], Step [   1/1], Loss: 1.0631 Validation Loss: 1.2894\n",
      "Epoch [ 360/500], Step [   1/1], Loss: 1.0625 Validation Loss: 1.2891\n",
      "Epoch [ 361/500], Step [   1/1], Loss: 1.0618 Validation Loss: 1.2890\n",
      "Epoch [ 362/500], Step [   1/1], Loss: 1.0614 Validation Loss: 1.2889\n",
      "Epoch [ 363/500], Step [   1/1], Loss: 1.0610 Validation Loss: 1.2888\n",
      "Epoch [ 364/500], Step [   1/1], Loss: 1.0606 Validation Loss: 1.2886\n",
      "Epoch [ 365/500], Step [   1/1], Loss: 1.0602 Validation Loss: 1.2885\n",
      "Epoch [ 366/500], Step [   1/1], Loss: 1.0598 Validation Loss: 1.2884\n",
      "Epoch [ 367/500], Step [   1/1], Loss: 1.0594 Validation Loss: 1.2883\n",
      "Epoch [ 368/500], Step [   1/1], Loss: 1.0590 Validation Loss: 1.2881\n",
      "Epoch [ 369/500], Step [   1/1], Loss: 1.0586 Validation Loss: 1.2880\n",
      "Epoch [ 370/500], Step [   1/1], Loss: 1.0581 Validation Loss: 1.2879\n",
      "Epoch [ 371/500], Step [   1/1], Loss: 1.0577 Validation Loss: 1.2878\n",
      "Epoch [ 372/500], Step [   1/1], Loss: 1.0573 Validation Loss: 1.2877\n",
      "Epoch [ 373/500], Step [   1/1], Loss: 1.0569 Validation Loss: 1.2875\n",
      "Epoch [ 374/500], Step [   1/1], Loss: 1.0565 Validation Loss: 1.2874\n",
      "Epoch [ 375/500], Step [   1/1], Loss: 1.0561 Validation Loss: 1.2873\n",
      "Epoch [ 376/500], Step [   1/1], Loss: 1.0557 Validation Loss: 1.2872\n",
      "Epoch [ 377/500], Step [   1/1], Loss: 1.0553 Validation Loss: 1.2870\n",
      "Epoch [ 378/500], Step [   1/1], Loss: 1.0549 Validation Loss: 1.2869\n",
      "Epoch [ 379/500], Step [   1/1], Loss: 1.0545 Validation Loss: 1.2868\n",
      "Epoch [ 380/500], Step [   1/1], Loss: 1.0541 Validation Loss: 1.2867\n",
      "Epoch [ 381/500], Step [   1/1], Loss: 1.0537 Validation Loss: 1.2866\n",
      "Epoch [ 382/500], Step [   1/1], Loss: 1.0533 Validation Loss: 1.2865\n",
      "Epoch [ 383/500], Step [   1/1], Loss: 1.0529 Validation Loss: 1.2863\n",
      "Epoch [ 384/500], Step [   1/1], Loss: 1.0525 Validation Loss: 1.2862\n",
      "Epoch [ 385/500], Step [   1/1], Loss: 1.0521 Validation Loss: 1.2861\n",
      "Epoch [ 386/500], Step [   1/1], Loss: 1.0517 Validation Loss: 1.2860\n",
      "Epoch [ 387/500], Step [   1/1], Loss: 1.0513 Validation Loss: 1.2859\n",
      "Epoch [ 388/500], Step [   1/1], Loss: 1.0509 Validation Loss: 1.2857\n",
      "Epoch [ 389/500], Step [   1/1], Loss: 1.0505 Validation Loss: 1.2856\n",
      "Epoch [ 390/500], Step [   1/1], Loss: 1.0501 Validation Loss: 1.2854\n",
      "Epoch [ 391/500], Step [   1/1], Loss: 1.0497 Validation Loss: 1.2853\n",
      "Epoch [ 392/500], Step [   1/1], Loss: 1.0493 Validation Loss: 1.2851\n",
      "Epoch [ 393/500], Step [   1/1], Loss: 1.0489 Validation Loss: 1.2850\n",
      "Epoch [ 394/500], Step [   1/1], Loss: 1.0485 Validation Loss: 1.2849\n",
      "Epoch [ 395/500], Step [   1/1], Loss: 1.0481 Validation Loss: 1.2847\n",
      "Epoch [ 396/500], Step [   1/1], Loss: 1.0477 Validation Loss: 1.2846\n",
      "Epoch [ 397/500], Step [   1/1], Loss: 1.0474 Validation Loss: 1.2845\n",
      "Epoch [ 398/500], Step [   1/1], Loss: 1.0470 Validation Loss: 1.2844\n",
      "Epoch [ 399/500], Step [   1/1], Loss: 1.0466 Validation Loss: 1.2843\n",
      "Epoch [ 400/500], Step [   1/1], Loss: 1.0462 Validation Loss: 1.2841\n",
      "Epoch [ 401/500], Step [   1/1], Loss: 1.0458 Validation Loss: 1.2840\n",
      "Epoch [ 402/500], Step [   1/1], Loss: 1.0455 Validation Loss: 1.2839\n",
      "Epoch [ 403/500], Step [   1/1], Loss: 1.0452 Validation Loss: 1.2838\n",
      "Epoch [ 404/500], Step [   1/1], Loss: 1.0449 Validation Loss: 1.2837\n",
      "Epoch [ 405/500], Step [   1/1], Loss: 1.0446 Validation Loss: 1.2836\n",
      "Epoch [ 406/500], Step [   1/1], Loss: 1.0443 Validation Loss: 1.2835\n",
      "Epoch [ 407/500], Step [   1/1], Loss: 1.0440 Validation Loss: 1.2834\n",
      "Epoch [ 408/500], Step [   1/1], Loss: 1.0436 Validation Loss: 1.2833\n",
      "Epoch [ 409/500], Step [   1/1], Loss: 1.0433 Validation Loss: 1.2832\n",
      "Epoch [ 410/500], Step [   1/1], Loss: 1.0430 Validation Loss: 1.2831\n",
      "Epoch [ 411/500], Step [   1/1], Loss: 1.0427 Validation Loss: 1.2830\n",
      "Epoch [ 412/500], Step [   1/1], Loss: 1.0424 Validation Loss: 1.2829\n",
      "Epoch [ 413/500], Step [   1/1], Loss: 1.0421 Validation Loss: 1.2828\n",
      "Epoch [ 414/500], Step [   1/1], Loss: 1.0418 Validation Loss: 1.2827\n",
      "Epoch [ 415/500], Step [   1/1], Loss: 1.0415 Validation Loss: 1.2826\n",
      "Epoch [ 416/500], Step [   1/1], Loss: 1.0412 Validation Loss: 1.2825\n",
      "Epoch [ 417/500], Step [   1/1], Loss: 1.0409 Validation Loss: 1.2824\n",
      "Epoch [ 418/500], Step [   1/1], Loss: 1.0406 Validation Loss: 1.2823\n",
      "Epoch [ 419/500], Step [   1/1], Loss: 1.0403 Validation Loss: 1.2822\n",
      "Epoch [ 420/500], Step [   1/1], Loss: 1.0400 Validation Loss: 1.2821\n",
      "Epoch [ 421/500], Step [   1/1], Loss: 1.0397 Validation Loss: 1.2820\n",
      "Epoch [ 422/500], Step [   1/1], Loss: 1.0394 Validation Loss: 1.2819\n",
      "Epoch [ 423/500], Step [   1/1], Loss: 1.0391 Validation Loss: 1.2818\n",
      "Epoch [ 424/500], Step [   1/1], Loss: 1.0388 Validation Loss: 1.2817\n",
      "Epoch [ 425/500], Step [   1/1], Loss: 1.0385 Validation Loss: 1.2816\n",
      "Epoch [ 426/500], Step [   1/1], Loss: 1.0382 Validation Loss: 1.2815\n",
      "Epoch [ 427/500], Step [   1/1], Loss: 1.0379 Validation Loss: 1.2815\n",
      "Epoch [ 428/500], Step [   1/1], Loss: 1.0376 Validation Loss: 1.2814\n",
      "Epoch [ 429/500], Step [   1/1], Loss: 1.0373 Validation Loss: 1.2813\n",
      "Epoch [ 430/500], Step [   1/1], Loss: 1.0370 Validation Loss: 1.2812\n",
      "Epoch [ 431/500], Step [   1/1], Loss: 1.0367 Validation Loss: 1.2811\n",
      "Epoch [ 432/500], Step [   1/1], Loss: 1.0364 Validation Loss: 1.2810\n",
      "Epoch [ 433/500], Step [   1/1], Loss: 1.0362 Validation Loss: 1.2809\n",
      "Epoch [ 434/500], Step [   1/1], Loss: 1.0359 Validation Loss: 1.2808\n",
      "Epoch [ 435/500], Step [   1/1], Loss: 1.0356 Validation Loss: 1.2807\n",
      "Epoch [ 436/500], Step [   1/1], Loss: 1.0353 Validation Loss: 1.2806\n",
      "Epoch [ 437/500], Step [   1/1], Loss: 1.0350 Validation Loss: 1.2805\n",
      "Epoch [ 438/500], Step [   1/1], Loss: 1.0347 Validation Loss: 1.2804\n",
      "Epoch [ 439/500], Step [   1/1], Loss: 1.0344 Validation Loss: 1.2803\n",
      "Epoch [ 440/500], Step [   1/1], Loss: 1.0341 Validation Loss: 1.2803\n",
      "Epoch [ 441/500], Step [   1/1], Loss: 1.0338 Validation Loss: 1.2802\n",
      "Epoch [ 442/500], Step [   1/1], Loss: 1.0335 Validation Loss: 1.2801\n",
      "Epoch [ 443/500], Step [   1/1], Loss: 1.0332 Validation Loss: 1.2800\n",
      "Epoch [ 444/500], Step [   1/1], Loss: 1.0329 Validation Loss: 1.2799\n",
      "Epoch [ 445/500], Step [   1/1], Loss: 1.0326 Validation Loss: 1.2798\n",
      "Epoch [ 446/500], Step [   1/1], Loss: 1.0323 Validation Loss: 1.2797\n",
      "Epoch [ 447/500], Step [   1/1], Loss: 1.0320 Validation Loss: 1.2797\n",
      "Epoch [ 448/500], Step [   1/1], Loss: 1.0318 Validation Loss: 1.2796\n",
      "Epoch [ 449/500], Step [   1/1], Loss: 1.0315 Validation Loss: 1.2795\n",
      "Epoch [ 450/500], Step [   1/1], Loss: 1.0312 Validation Loss: 1.2794\n",
      "Epoch [ 451/500], Step [   1/1], Loss: 1.0309 Validation Loss: 1.2793\n",
      "Epoch [ 452/500], Step [   1/1], Loss: 1.0306 Validation Loss: 1.2793\n",
      "Epoch [ 453/500], Step [   1/1], Loss: 1.0303 Validation Loss: 1.2792\n",
      "Epoch [ 454/500], Step [   1/1], Loss: 1.0300 Validation Loss: 1.2791\n",
      "Epoch [ 455/500], Step [   1/1], Loss: 1.0297 Validation Loss: 1.2790\n",
      "Epoch [ 456/500], Step [   1/1], Loss: 1.0294 Validation Loss: 1.2789\n",
      "Epoch [ 457/500], Step [   1/1], Loss: 1.0291 Validation Loss: 1.2789\n",
      "Epoch [ 458/500], Step [   1/1], Loss: 1.0288 Validation Loss: 1.2788\n",
      "Epoch [ 459/500], Step [   1/1], Loss: 1.0285 Validation Loss: 1.2787\n",
      "Epoch [ 460/500], Step [   1/1], Loss: 1.0282 Validation Loss: 1.2786\n",
      "Epoch [ 461/500], Step [   1/1], Loss: 1.0280 Validation Loss: 1.2785\n",
      "Epoch [ 462/500], Step [   1/1], Loss: 1.0277 Validation Loss: 1.2785\n",
      "Epoch [ 463/500], Step [   1/1], Loss: 1.0274 Validation Loss: 1.2784\n",
      "Epoch [ 464/500], Step [   1/1], Loss: 1.0271 Validation Loss: 1.2783\n",
      "Epoch [ 465/500], Step [   1/1], Loss: 1.0268 Validation Loss: 1.2782\n",
      "Epoch [ 466/500], Step [   1/1], Loss: 1.0265 Validation Loss: 1.2781\n",
      "Epoch [ 467/500], Step [   1/1], Loss: 1.0262 Validation Loss: 1.2781\n",
      "Epoch [ 468/500], Step [   1/1], Loss: 1.0259 Validation Loss: 1.2780\n",
      "Epoch [ 469/500], Step [   1/1], Loss: 1.0256 Validation Loss: 1.2779\n",
      "Epoch [ 470/500], Step [   1/1], Loss: 1.0254 Validation Loss: 1.2778\n",
      "Epoch [ 471/500], Step [   1/1], Loss: 1.0251 Validation Loss: 1.2777\n",
      "Epoch [ 472/500], Step [   1/1], Loss: 1.0248 Validation Loss: 1.2776\n",
      "Epoch [ 473/500], Step [   1/1], Loss: 1.0245 Validation Loss: 1.2775\n",
      "Epoch [ 474/500], Step [   1/1], Loss: 1.0242 Validation Loss: 1.2775\n",
      "Epoch [ 475/500], Step [   1/1], Loss: 1.0239 Validation Loss: 1.2774\n",
      "Epoch [ 476/500], Step [   1/1], Loss: 1.0236 Validation Loss: 1.2773\n",
      "Epoch [ 477/500], Step [   1/1], Loss: 1.0233 Validation Loss: 1.2772\n",
      "Epoch [ 478/500], Step [   1/1], Loss: 1.0231 Validation Loss: 1.2771\n",
      "Epoch [ 479/500], Step [   1/1], Loss: 1.0228 Validation Loss: 1.2771\n",
      "Epoch [ 480/500], Step [   1/1], Loss: 1.0225 Validation Loss: 1.2770\n",
      "Epoch [ 481/500], Step [   1/1], Loss: 1.0222 Validation Loss: 1.2769\n",
      "Epoch [ 482/500], Step [   1/1], Loss: 1.0220 Validation Loss: 1.2769\n",
      "Epoch [ 483/500], Step [   1/1], Loss: 1.0218 Validation Loss: 1.2768\n",
      "Epoch [ 484/500], Step [   1/1], Loss: 1.0216 Validation Loss: 1.2768\n",
      "Epoch [ 485/500], Step [   1/1], Loss: 1.0215 Validation Loss: 1.2767\n",
      "Epoch [ 486/500], Step [   1/1], Loss: 1.0213 Validation Loss: 1.2767\n",
      "Epoch [ 487/500], Step [   1/1], Loss: 1.0211 Validation Loss: 1.2766\n",
      "Epoch [ 488/500], Step [   1/1], Loss: 1.0209 Validation Loss: 1.2766\n",
      "Epoch [ 489/500], Step [   1/1], Loss: 1.0207 Validation Loss: 1.2766\n",
      "Epoch [ 490/500], Step [   1/1], Loss: 1.0205 Validation Loss: 1.2765\n",
      "Epoch [ 491/500], Step [   1/1], Loss: 1.0204 Validation Loss: 1.2765\n",
      "Epoch [ 492/500], Step [   1/1], Loss: 1.0202 Validation Loss: 1.2764\n",
      "Epoch [ 493/500], Step [   1/1], Loss: 1.0200 Validation Loss: 1.2764\n",
      "Epoch [ 494/500], Step [   1/1], Loss: 1.0198 Validation Loss: 1.2763\n",
      "Epoch [ 495/500], Step [   1/1], Loss: 1.0196 Validation Loss: 1.2763\n",
      "Epoch [ 496/500], Step [   1/1], Loss: 1.0194 Validation Loss: 1.2762\n",
      "Epoch [ 497/500], Step [   1/1], Loss: 1.0193 Validation Loss: 1.2762\n",
      "Epoch [ 498/500], Step [   1/1], Loss: 1.0191 Validation Loss: 1.2761\n",
      "Epoch [ 499/500], Step [   1/1], Loss: 1.0189 Validation Loss: 1.2761\n",
      "Epoch [ 500/500], Step [   1/1], Loss: 1.0187 Validation Loss: 1.2760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import lightning as L\n",
    "# trainer = L.Trainer(\n",
    "#     max_epochs=10,\n",
    "#     accelerator='cpu',\n",
    "#     log_every_n_steps=1        \n",
    "# )\n",
    "# trainer.fit(model=model, train_dataloaders=train_dl)\n",
    "\n",
    "optimizer_backbone, lr_scheduler_backbone = model.configure_backbone_optimizers(step_size=step_size_bb, gamma=gamma_bb, learning_rate=learning_rate_bb)\n",
    "optimizer_downstream, lr_scheduler_downstream = model.configure_head_optimizers(step_size=step_size_ds, gamma=gamma_ds, learning_rate=learning_rate_ds)\n",
    "\n",
    "train_errors = []\n",
    "validation_errors = []\n",
    "best_val_loss = 500\n",
    "n_total_steps = len(train_dl)\n",
    "for epoch in range(num_epoch):\n",
    "    # Treinamento\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, batch in enumerate(train_dl):\n",
    "        loss = model.training_step(batch)\n",
    "        train_loss += loss.item()\n",
    "        optimizer_backbone.zero_grad()\n",
    "        optimizer_downstream.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_backbone.step()\n",
    "        optimizer_downstream.step()\n",
    "        \n",
    "        if (i+1) % math.floor(n_total_steps/printQtd) == 0:\n",
    "            print (f'Epoch [{epoch+1:4d}/{num_epoch}], Step [{i+1:4d}/{n_total_steps}], Loss: {loss.item():.4f}', end= \"\" if n_total_steps/printQtd+i >= n_total_steps else \"\\n\")\n",
    "\n",
    "    lr_scheduler_backbone.step()\n",
    "    lr_scheduler_downstream.step()\n",
    "\n",
    "    # Validação\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dl:\n",
    "            val_loss += model.validation_step(batch)\n",
    "    \n",
    "    val_loss /= len(test_dl)\n",
    "    print(f' Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "    train_errors.append(train_loss/len(train_dl))\n",
    "    validation_errors.append(val_loss.item())\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model.state_dict()  # Salva os parâmetros do modelo\n",
    "\n",
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 45.833333333333336 %\n",
      "Accuracy of Run (4/4 | 5): 100.0 %\n",
      "Accuracy of Sit (0/4 | 0): 0.0 %\n",
      "Accuracy of Stair-down (3/4 | 4): 75.0 %\n",
      "Accuracy of Stair-up (0/4 | 0): 0.0 %\n",
      "Accuracy of Stand (0/4 | 0): 0.0 %\n",
      "Accuracy of Walk (4/4 | 15): 100.0 %\n"
     ]
    }
   ],
   "source": [
    "accTotal = 0\n",
    "predicted_values = []\n",
    "real_values = []\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(num_classes)]\n",
    "    n_class_samples = [0 for i in range(num_classes)]\n",
    "    n_each_class_samples = [0 for i in range(num_classes)]\n",
    "\n",
    "    for data, labels in test_dl:\n",
    "        outputs = model(data)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        for pred, real in zip (predicted, labels):\n",
    "            predicted_values.append(pred.item())\n",
    "            real_values.append(real.item())\n",
    "\n",
    "        for i in range(labels.shape[0]):\n",
    "            label = labels[i]\n",
    "            pred  = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "            n_each_class_samples[pred] += 1\n",
    "\n",
    "    accTotal = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {accTotal} %')\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {test_ds.getLabel(i)} ({n_class_correct[i]}/{n_class_samples[i]} | {n_each_class_samples[i]}): {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salva Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_full_model(accuracy=accTotal, batch_size=batch_size, num_epoch=num_epoch)\n",
    "\n",
    "pred_reports = pd.DataFrame({\n",
    "    Sets.REAL.value: real_values,\n",
    "    Sets.PREDICTION.value : predicted_values\n",
    "})\n",
    "pred_reports.to_csv(f\"{path_reports}/predictions_{ModelTypes.DOWNSTREAM.value}.dat\", sep=\" \", index=False)\n",
    "\n",
    "train_reports = pd.DataFrame({\n",
    "    Sets.TRAIN.value : train_errors,\n",
    "    Sets.VALIDATION.value : validation_errors\n",
    "})\n",
    "train_reports.to_csv(f\"{path_reports}/errors_{ModelTypes.DOWNSTREAM.value}.dat\", sep=\" \", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
